{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from thingsvision import get_extractor\n",
    "from thingsvision.utils.storing import save_features\n",
    "from thingsvision.utils.data import ImageDataset, DataLoader\n",
    "from thingsvision.core.extraction import center_features\n",
    "\n",
    "# from google.colab import drive\n",
    "from typing import Any, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_path = '/home/yifan/projects/deepdebugertool/thingsvision/imgs/'\n",
    "full_output_path = '/home/yifan/projects/deepdebugertool/thingsvision/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "                    extractor: Any,\n",
    "                    module_name: str,\n",
    "                    image_path: str,\n",
    "                    out_path: str,\n",
    "                    batch_size: int,\n",
    "                    flatten_activations: bool,\n",
    "                    apply_center_crop: bool,\n",
    "                    class_names: List[str]=None,\n",
    "                    file_names: List[str]=None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Extract features for a single layer.\"\"\"                                    \n",
    "    dataset = ImageDataset(\n",
    "        root=image_path,\n",
    "        out_path=out_path,\n",
    "        backend=extractor.get_backend(),\n",
    "        transforms=extractor.get_transformations(apply_center_crop=apply_center_crop, resize_dim=256, crop_dim=224),\n",
    "        class_names=class_names,\n",
    "        file_names=file_names,\n",
    "    )\n",
    "    batches = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=batch_size, \n",
    "        backend=extractor.get_backend(),\n",
    "        )\n",
    "    features = extractor.extract_features(\n",
    "                    batches=batches,\n",
    "                    module_name=module_name,\n",
    "                    flatten_acts=flatten_activations,\n",
    "    )\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_all_layers(\n",
    "                        model_name: str,\n",
    "                        extractor: Any,\n",
    "                        image_path: str,\n",
    "                        out_path: str,\n",
    "                        batch_size: int,\n",
    "                        flatten_activations: bool,\n",
    "                        apply_center_crop: bool,\n",
    "                        layer: Any=nn.Linear,\n",
    "                        class_names: List[str]=None,\n",
    "                        file_names: List[str]=None,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Extract features for all selected layers and save them to disk.\"\"\"\n",
    "    features_per_layer = {}\n",
    "    for l, (module_name, module) in enumerate(extractor.model.named_modules(), start=1):\n",
    "        if isinstance(module, layer):\n",
    "            # extract features for layer \"module_name\"\n",
    "            features = extract_features(\n",
    "                                        extractor=extractor,\n",
    "                                        module_name=module_name,\n",
    "                                        image_path=image_path,\n",
    "                                        out_path=out_path,\n",
    "                                        batch_size=batch_size,\n",
    "                                        flatten_activations=flatten_activations,\n",
    "                                        apply_center_crop=apply_center_crop,\n",
    "                                        class_names=class_names,\n",
    "                                        file_names=file_names,\n",
    "            )\n",
    "            # replace with e.g., [f'conv_{l:02d}'] or [f'fc_{l:02d}']\n",
    "            features_per_layer[f'layer_{l:02d}'] = features\n",
    "            # save features to disk\n",
    "            save_features(features, out_path=f'{out_path}/features_{model_name}_{module_name}', file_format='npy')\n",
    "    return features_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = True # use pretrained model weights\n",
    "model_path = '/home/yifan/dataset/clean/pairflip/cifar10/0/Model/Epoch_200/subject_model.pth' # if pretrained = False (i.e., randomly initialized weights) set path to model weights\n",
    "batch_size = 32 # use a power of two (this can be any size, depending on the number of images for which you aim to extract features)\n",
    "apply_center_crop = True # center crop images (set to False, if you don't want to center-crop images)\n",
    "flatten_activations = True # whether or not features (e.g., of Conv layers) should be flattened\n",
    "class_names = ['horse','truck','car','frog','cat','dog','plane']  # optional list of class names for class dataset\n",
    "file_names = None # optional list of file names according to which features should be sorted\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "GPU_ID = 0\n",
    "# device = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name = 'resnet18' \n",
    "# specify model source \n",
    "# we use torchvision here (https://pytorch.org/vision/stable/models.html)\n",
    "source = 'torchvision'\n",
    "# initialize the extractor\n",
    "extractor = get_extractor( \n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            model_path=None,\n",
    "            device=device,\n",
    "            source=source\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = 'layer4.1.bn2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Creating dataset.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0038039684295654297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batch",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc90e1bc07a45449e0d2a29cbf3a0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Features successfully extracted for all 13 images in the database.\n",
      "...Features shape: (13, 25088)\n",
      "...Features successfully saved to disk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract features for a single layer (e.g., penultimate)\n",
    "features = extract_features(\n",
    "                            extractor=extractor,\n",
    "                            module_name=module_name,\n",
    "                            image_path=full_image_path,\n",
    "                            out_path=full_output_path,\n",
    "                            batch_size=batch_size,\n",
    "                            flatten_activations=flatten_activations,\n",
    "                            apply_center_crop=apply_center_crop,\n",
    "                            class_names=class_names,\n",
    "                            file_names=file_names,\n",
    ")\n",
    "\n",
    "# apply centering (not necessary, but may be desirable, depending on the analysis)\n",
    "features = center_features(features)\n",
    "\n",
    "# save features to disk\n",
    "save_features(features, out_path=f'{full_output_path}/features_{model_name}_{module_name}', file_format='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thingsvision.core.rsa import compute_rdm, plot_rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Creating dataset.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005589723587036133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batch",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b1fdc010354a90963df959f01749ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Features successfully extracted for all 13 images in the database.\n",
      "...Features shape: (13, 25088)\n",
      "...Features successfully saved to disk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "clip_features = extract_features(\n",
    "                            extractor=extractor,\n",
    "                            module_name=module_name,\n",
    "                            image_path=full_image_path,\n",
    "                            out_path=full_output_path,\n",
    "                            batch_size=batch_size,\n",
    "                            flatten_activations=flatten_activations,\n",
    "                            apply_center_crop=apply_center_crop,\n",
    "                            class_names=class_names,\n",
    "                            file_names=file_names,\n",
    ")\n",
    "\n",
    "# apply centering (not necessary, but may be desirable, depending on the analysis)\n",
    "clip_features = center_features(clip_features)\n",
    "\n",
    "# save features to disk\n",
    "save_features(clip_features, out_path=f'{full_output_path}/features_{model_name}_{module_name}', file_format='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm = compute_rdm(clip_features, method='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 9.2542642e-01, 9.2135382e-01, 1.0031199e+00,\n",
       "        1.2158731e+00, 1.0009238e+00, 1.2223837e+00, 1.0815884e+00,\n",
       "        1.0780226e+00, 1.1088941e+00, 1.0143086e+00, 1.1849864e+00,\n",
       "        1.1794584e+00],\n",
       "       [9.2542642e-01, 5.9604645e-08, 9.6646756e-01, 7.8729630e-01,\n",
       "        1.1799173e+00, 1.1857766e+00, 1.1989305e+00, 1.0773959e+00,\n",
       "        1.1202741e+00, 1.1615032e+00, 9.5259577e-01, 1.2283158e+00,\n",
       "        1.1171916e+00],\n",
       "       [9.2135382e-01, 9.6646756e-01, 0.0000000e+00, 9.3620831e-01,\n",
       "        1.1298075e+00, 1.1575840e+00, 1.0615116e+00, 1.1289190e+00,\n",
       "        1.1944146e+00, 1.1320622e+00, 1.0984472e+00, 1.0863258e+00,\n",
       "        1.1327848e+00],\n",
       "       [1.0031199e+00, 7.8729630e-01, 9.3620831e-01, 0.0000000e+00,\n",
       "        1.2293463e+00, 1.1692133e+00, 1.1887636e+00, 1.0799038e+00,\n",
       "        1.0175102e+00, 1.1596608e+00, 1.1019015e+00, 1.1819472e+00,\n",
       "        1.1328762e+00],\n",
       "       [1.2158731e+00, 1.1799173e+00, 1.1298075e+00, 1.2293463e+00,\n",
       "        0.0000000e+00, 9.3231118e-01, 9.0966719e-01, 1.0852977e+00,\n",
       "        1.1809952e+00, 1.0269719e+00, 1.1627357e+00, 9.7579956e-01,\n",
       "        1.0554155e+00],\n",
       "       [1.0009238e+00, 1.1857766e+00, 1.1575840e+00, 1.1692133e+00,\n",
       "        9.3231118e-01, 0.0000000e+00, 1.0461290e+00, 1.1206558e+00,\n",
       "        1.1019628e+00, 1.1324674e+00, 1.1417875e+00, 1.1032833e+00,\n",
       "        1.0698242e+00],\n",
       "       [1.2223837e+00, 1.1989305e+00, 1.0615116e+00, 1.1887636e+00,\n",
       "        9.0966719e-01, 1.0461290e+00, 0.0000000e+00, 1.1124182e+00,\n",
       "        1.1332638e+00, 1.0821500e+00, 1.2074158e+00, 8.9720345e-01,\n",
       "        8.9238888e-01],\n",
       "       [1.0815884e+00, 1.0773959e+00, 1.1289190e+00, 1.0799038e+00,\n",
       "        1.0852977e+00, 1.1206558e+00, 1.1124182e+00, 0.0000000e+00,\n",
       "        1.0552243e+00, 9.6488148e-01, 1.0497265e+00, 1.0598587e+00,\n",
       "        1.1080461e+00],\n",
       "       [1.0780226e+00, 1.1202741e+00, 1.1944146e+00, 1.0175102e+00,\n",
       "        1.1809952e+00, 1.1019628e+00, 1.1332638e+00, 1.0552243e+00,\n",
       "        1.7881393e-07, 1.0411972e+00, 8.8798630e-01, 1.1304232e+00,\n",
       "        1.1309335e+00],\n",
       "       [1.1088941e+00, 1.1615032e+00, 1.1320622e+00, 1.1596608e+00,\n",
       "        1.0269719e+00, 1.1324674e+00, 1.0821500e+00, 9.6488148e-01,\n",
       "        1.0411972e+00, 2.3841858e-07, 1.0533223e+00, 1.0577004e+00,\n",
       "        1.1132214e+00],\n",
       "       [1.0143086e+00, 9.5259577e-01, 1.0984472e+00, 1.1019015e+00,\n",
       "        1.1627357e+00, 1.1417875e+00, 1.2074158e+00, 1.0497265e+00,\n",
       "        8.8798630e-01, 1.0533223e+00, 0.0000000e+00, 1.2358034e+00,\n",
       "        1.1219891e+00],\n",
       "       [1.1849864e+00, 1.2283158e+00, 1.0863258e+00, 1.1819472e+00,\n",
       "        9.7579956e-01, 1.1032833e+00, 8.9720345e-01, 1.0598587e+00,\n",
       "        1.1304232e+00, 1.0577004e+00, 1.2358034e+00, 1.1920929e-07,\n",
       "        8.5689890e-01],\n",
       "       [1.1794584e+00, 1.1171916e+00, 1.1327848e+00, 1.1328762e+00,\n",
       "        1.0554155e+00, 1.0698242e+00, 8.9238888e-01, 1.1080461e+00,\n",
       "        1.1309335e+00, 1.1132214e+00, 1.1219891e+00, 8.5689890e-01,\n",
       "        1.7881393e-07]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot rdm\n",
    "plot_rdm(\n",
    "        full_output_path,\n",
    "        clip_features,\n",
    "        method='correlation',\n",
    "        format='.png', # '.jpg'\n",
    "        colormap='cividis',\n",
    "        show_plot=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thingsvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1e0cb817811dd1a7baa3e4b804338a134a084c8c47e0231e75fc7484afa1e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
